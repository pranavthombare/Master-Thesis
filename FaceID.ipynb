{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceID.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "66tm_GR-Q8cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir faceid_train\n",
        "!mkdir faceid_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKW5B86iRNOy",
        "colab_type": "code",
        "outputId": "aef2e677-eb88-4eaf-d593-44728f0b21dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5-1qW_kRaVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link_list=[\"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(151751).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(153054).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(154211).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(160440).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(160931).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(161342).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(163349).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(164248).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(141550).zip\", \\\n",
        "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(142154).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(142457).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(143016).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(132824).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(133201).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(133846).zip\", \\\n",
        "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(134239).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(134757).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(140516).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(143345).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(144316).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(145150).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(145623).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(150303).zip\", \\\n",
        "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(150650).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(151337).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(151650).zip\"]\n",
        "val_list=[\"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(152717).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(153532).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(154129).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(154728).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(155357).zip\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE-JCcP3RlJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, io\n",
        "for link in link_list:\n",
        "  r = requests.get(link, stream=True)\n",
        "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "  z.extractall(\"faceid_train\")\n",
        "for link in val_list:\n",
        "  r = requests.get(link, stream=True)\n",
        "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "  z.extractall(\"faceid_val\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5oRNHNLR70_",
        "colab_type": "text"
      },
      "source": [
        "# Input preprocessing.\n",
        "Here we create some functions that will create the input couple for our model, both correct and wrong couples. I created functions to have both depth-only input and RGBD inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PuukrvXR-Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGAD5vzUSA0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_couple(file_path):\n",
        "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    while folder == \"datalab\":\n",
        "      folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "  #  print(folder)\n",
        "    mat=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue \n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat = np.asarray(mat)\n",
        "    mat_small=mat[140:340,220:420]\n",
        "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
        "#    plt.imshow(mat_small)\n",
        "#    plt.show()\n",
        "    \n",
        "    mat2=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue \n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat2[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat2 = np.asarray(mat2)\n",
        "    mat2_small=mat2[140:340,220:420]\n",
        "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
        "#    plt.imshow(mat2_small)\n",
        "#    plt.show()\n",
        "    return np.array([mat_small, mat2_small])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRPXGUD2SB-d",
        "colab_type": "code",
        "outputId": "c66cbe37-d2a2-492e-94bf-bb07460d716f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print(create_couple(\"faceid_train/\"))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0.11292195  0.11292195  0.11292195 ...  0.11292195  0.11292195\n",
            "    0.11292195]\n",
            "  [ 0.11292195  0.11292195  0.11292195 ...  0.11292195  0.11292195\n",
            "    0.11292195]\n",
            "  [ 0.11292195  0.11292195  0.11292195 ...  0.11292195  0.11292195\n",
            "    0.11292195]\n",
            "  ...\n",
            "  [-0.08541138 -0.08541138 -0.08541138 ... -0.07624471 -0.07624471\n",
            "   -0.07624471]\n",
            "  [-0.08791137 -0.08541138 -0.08541138 ... -0.07624471 -0.07624471\n",
            "   -0.07624471]\n",
            "  [-0.08791137 -0.08791137 -0.08791137 ... -0.07874471 -0.07624471\n",
            "   -0.07874471]]\n",
            "\n",
            " [[ 0.14325552  0.14325552  0.14325552 ...  0.14325552  0.14325552\n",
            "    0.14325552]\n",
            "  [ 0.14325552  0.14325552  0.14325552 ...  0.14325552  0.14325552\n",
            "    0.14325552]\n",
            "  [ 0.14325552  0.14325552  0.14325552 ...  0.14325552  0.14325552\n",
            "    0.14325552]\n",
            "  ...\n",
            "  [-0.06174449 -0.05924449 -0.05924449 ... -0.03924449 -0.04174449\n",
            "   -0.03924449]\n",
            "  [-0.06174449 -0.06174449 -0.06174449 ... -0.04174449 -0.04174449\n",
            "   -0.04174449]\n",
            "  [-0.06341115 -0.06341115 -0.06174449 ... -0.04341115 -0.04341115\n",
            "   -0.04341115]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERg_wucYSDvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_couple_rgbd(file_path):\n",
        "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    while folder == \"datalab\":\n",
        "      folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "  #  print(folder)\n",
        "    mat=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue    \n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat = np.asarray(mat)\n",
        "    mat_small=mat[140:340,220:420]\n",
        "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
        "    img.thumbnail((640,480))\n",
        "    img = np.asarray(img)\n",
        "    img = img[140:340,220:420]\n",
        "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
        "#    plt.imshow(mat_small)\n",
        "#    plt.show()\n",
        "#    plt.imshow(img)\n",
        "#    plt.show()\n",
        "    \n",
        "    \n",
        "    mat2=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue\n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat2[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat2 = np.asarray(mat2)\n",
        "    mat2_small=mat2[140:340,220:420]\n",
        "    img2 = Image.open(depth_file[:-5] + \"c.bmp\")\n",
        "    img2.thumbnail((640,480))\n",
        "    img2 = np.asarray(img2)\n",
        "    img2 = img2[160:360,240:440]\n",
        "\n",
        " #   plt.imshow(img2)\n",
        " #   plt.show()\n",
        "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
        " #   plt.imshow(mat2_small)\n",
        " #   plt.show()\n",
        "    \n",
        "    full1 = np.zeros((200,200,4))\n",
        "    full1[:,:,:3] = img[:,:,:3]\n",
        "    full1[:,:,3] = mat_small\n",
        "    \n",
        "    full2 = np.zeros((200,200,4))\n",
        "    full2[:,:,:3] = img2[:,:,:3]\n",
        "    full2[:,:,3] = mat2_small\n",
        "    return np.array([full1, full2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuurpuDTo0S",
        "colab_type": "code",
        "outputId": "c03b69b2-7e5a-4482-af55-27c538e7cbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "create_couple_rgbd(\"faceid_val/\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 1.75000000e+02,  1.59000000e+02,  1.30000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.75000000e+02,  1.59000000e+02,  1.32000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.75000000e+02,  1.58000000e+02,  1.32000000e+02,\n",
              "           1.08113810e-01],\n",
              "         ...,\n",
              "         [ 1.52000000e+02,  1.45000000e+02,  1.21000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.51000000e+02,  1.45000000e+02,  1.21000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.51000000e+02,  1.44000000e+02,  1.19000000e+02,\n",
              "           1.08113810e-01]],\n",
              "\n",
              "        [[ 1.74000000e+02,  1.58000000e+02,  1.30000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.74000000e+02,  1.58000000e+02,  1.31000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.73000000e+02,  1.59000000e+02,  1.32000000e+02,\n",
              "           1.08113810e-01],\n",
              "         ...,\n",
              "         [ 1.51000000e+02,  1.45000000e+02,  1.21000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.50000000e+02,  1.45000000e+02,  1.20000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.49000000e+02,  1.45000000e+02,  1.18000000e+02,\n",
              "           1.08113810e-01]],\n",
              "\n",
              "        [[ 1.73000000e+02,  1.61000000e+02,  1.30000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.72000000e+02,  1.59000000e+02,  1.31000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.72000000e+02,  1.59000000e+02,  1.32000000e+02,\n",
              "           1.08113810e-01],\n",
              "         ...,\n",
              "         [ 1.51000000e+02,  1.43000000e+02,  1.19000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.50000000e+02,  1.44000000e+02,  1.19000000e+02,\n",
              "           1.08113810e-01],\n",
              "         [ 1.49000000e+02,  1.45000000e+02,  1.20000000e+02,\n",
              "           1.08113810e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.22000000e+02,  1.20000000e+02,  1.55000000e+02,\n",
              "          -8.77195224e-02],\n",
              "         [ 1.21000000e+02,  1.21000000e+02,  1.54000000e+02,\n",
              "          -8.77195224e-02],\n",
              "         [ 1.24000000e+02,  1.20000000e+02,  1.50000000e+02,\n",
              "          -8.77195224e-02],\n",
              "         ...,\n",
              "         [ 1.47000000e+02,  1.48000000e+02,  1.88000000e+02,\n",
              "          -8.77195224e-02],\n",
              "         [ 1.44000000e+02,  1.45000000e+02,  1.88000000e+02,\n",
              "          -8.77195224e-02],\n",
              "         [ 1.44000000e+02,  1.43000000e+02,  1.89000000e+02,\n",
              "          -8.77195224e-02]],\n",
              "\n",
              "        [[ 1.26000000e+02,  1.25000000e+02,  1.57000000e+02,\n",
              "          -9.02195200e-02],\n",
              "         [ 1.25000000e+02,  1.20000000e+02,  1.57000000e+02,\n",
              "          -9.27195251e-02],\n",
              "         [ 1.27000000e+02,  1.18000000e+02,  1.55000000e+02,\n",
              "          -9.02195200e-02],\n",
              "         ...,\n",
              "         [ 1.49000000e+02,  1.43000000e+02,  1.89000000e+02,\n",
              "          -9.02195200e-02],\n",
              "         [ 1.49000000e+02,  1.46000000e+02,  1.90000000e+02,\n",
              "          -9.02195200e-02],\n",
              "         [ 1.46000000e+02,  1.44000000e+02,  1.89000000e+02,\n",
              "          -9.02195200e-02]],\n",
              "\n",
              "        [[ 1.31000000e+02,  1.23000000e+02,  1.56000000e+02,\n",
              "          -9.27195251e-02],\n",
              "         [ 1.30000000e+02,  1.19000000e+02,  1.57000000e+02,\n",
              "          -9.27195251e-02],\n",
              "         [ 1.33000000e+02,  1.21000000e+02,  1.58000000e+02,\n",
              "          -9.27195251e-02],\n",
              "         ...,\n",
              "         [ 1.46000000e+02,  1.38000000e+02,  1.90000000e+02,\n",
              "          -9.43861902e-02],\n",
              "         [ 1.48000000e+02,  1.42000000e+02,  1.91000000e+02,\n",
              "          -9.27195251e-02],\n",
              "         [ 1.45000000e+02,  1.46000000e+02,  1.90000000e+02,\n",
              "          -9.27195251e-02]]],\n",
              "\n",
              "\n",
              "       [[[ 1.75000000e+02,  1.60000000e+02,  1.34000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.75000000e+02,  1.60000000e+02,  1.35000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.75000000e+02,  1.60000000e+02,  1.35000000e+02,\n",
              "           9.31304917e-02],\n",
              "         ...,\n",
              "         [ 1.54000000e+02,  1.46000000e+02,  1.24000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.54000000e+02,  1.46000000e+02,  1.22000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.54000000e+02,  1.45000000e+02,  1.20000000e+02,\n",
              "           9.31304917e-02]],\n",
              "\n",
              "        [[ 1.74000000e+02,  1.61000000e+02,  1.35000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.74000000e+02,  1.60000000e+02,  1.35000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.75000000e+02,  1.60000000e+02,  1.35000000e+02,\n",
              "           9.31304917e-02],\n",
              "         ...,\n",
              "         [ 1.54000000e+02,  1.47000000e+02,  1.25000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.54000000e+02,  1.47000000e+02,  1.25000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.54000000e+02,  1.45000000e+02,  1.23000000e+02,\n",
              "           9.31304917e-02]],\n",
              "\n",
              "        [[ 1.73000000e+02,  1.61000000e+02,  1.35000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.73000000e+02,  1.62000000e+02,  1.36000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.75000000e+02,  1.63000000e+02,  1.36000000e+02,\n",
              "           9.31304917e-02],\n",
              "         ...,\n",
              "         [ 1.53000000e+02,  1.49000000e+02,  1.25000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.54000000e+02,  1.48000000e+02,  1.26000000e+02,\n",
              "           9.31304917e-02],\n",
              "         [ 1.55000000e+02,  1.45000000e+02,  1.26000000e+02,\n",
              "           9.31304917e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.37000000e+02,  1.28000000e+02,  1.66000000e+02,\n",
              "          -8.93695056e-02],\n",
              "         [ 1.39000000e+02,  1.30000000e+02,  1.66000000e+02,\n",
              "          -8.68695080e-02],\n",
              "         [ 1.43000000e+02,  1.34000000e+02,  1.66000000e+02,\n",
              "          -8.68695080e-02],\n",
              "         ...,\n",
              "         [ 1.25000000e+02,  1.24000000e+02,  1.67000000e+02,\n",
              "          -9.35361758e-02],\n",
              "         [ 1.14000000e+02,  1.09000000e+02,  1.56000000e+02,\n",
              "          -9.60361734e-02],\n",
              "         [ 1.11000000e+02,  1.07000000e+02,  1.58000000e+02,\n",
              "          -9.60361734e-02]],\n",
              "\n",
              "        [[ 1.39000000e+02,  1.25000000e+02,  1.63000000e+02,\n",
              "          -8.93695056e-02],\n",
              "         [ 1.42000000e+02,  1.28000000e+02,  1.64000000e+02,\n",
              "          -8.93695056e-02],\n",
              "         [ 1.44000000e+02,  1.31000000e+02,  1.65000000e+02,\n",
              "          -8.93695056e-02],\n",
              "         ...,\n",
              "         [ 1.10000000e+02,  1.14000000e+02,  1.62000000e+02,\n",
              "          -9.60361734e-02],\n",
              "         [ 1.04000000e+02,  1.05000000e+02,  1.56000000e+02,\n",
              "          -9.85361710e-02],\n",
              "         [ 1.09000000e+02,  1.10000000e+02,  1.60000000e+02,\n",
              "          -9.85361710e-02]],\n",
              "\n",
              "        [[ 1.42000000e+02,  1.28000000e+02,  1.62000000e+02,\n",
              "          -9.18695033e-02],\n",
              "         [ 1.45000000e+02,  1.30000000e+02,  1.64000000e+02,\n",
              "          -8.93695056e-02],\n",
              "         [ 1.46000000e+02,  1.33000000e+02,  1.65000000e+02,\n",
              "          -8.93695056e-02],\n",
              "         ...,\n",
              "         [ 1.08000000e+02,  1.14000000e+02,  1.62000000e+02,\n",
              "          -9.85361710e-02],\n",
              "         [ 1.01000000e+02,  1.07000000e+02,  1.58000000e+02,\n",
              "          -9.85361710e-02],\n",
              "         [ 1.04000000e+02,  1.11000000e+02,  1.62000000e+02,\n",
              "          -1.00202844e-01]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owmH6YNpTrEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_wrong(file_path):\n",
        "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    while folder == \"datalab\":\n",
        "      folder=np.random.choice(glob.glob(file_path + \"*\"))    \n",
        "    mat=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue \n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat = np.asarray(mat)\n",
        "    mat_small=mat[140:340,220:420]\n",
        "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
        " #   plt.imshow(mat_small)\n",
        " #   plt.show()\n",
        "    \n",
        "    folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    while folder==folder2 or folder2==\"datalab\": #it activates if it chose the same folder\n",
        "        folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    mat2=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder2 + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue\n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat2[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat2 = np.asarray(mat2)\n",
        "    mat2_small=mat2[140:340,220:420]\n",
        "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
        " #   plt.imshow(mat2_small)\n",
        " #   plt.show()\n",
        "  \n",
        "    \n",
        "    return np.array([mat_small, mat2_small])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dKY9a-ETszu",
        "colab_type": "code",
        "outputId": "02e1e8bd-ec89-4314-94dc-c9bd3e9cb3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "create_wrong(\"faceid_train/\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.09965342,  0.09965342,  0.09965342, ...,  0.09965342,\n",
              "          0.09965342,  0.09965342],\n",
              "        [ 0.09965342,  0.09965342,  0.09965342, ...,  0.09965342,\n",
              "          0.09965342,  0.09965342],\n",
              "        [ 0.09965342,  0.09965342,  0.09965342, ...,  0.09965342,\n",
              "          0.09965342,  0.09965342],\n",
              "        ...,\n",
              "        [-0.06867991, -0.06867991, -0.08534658, ..., -0.09617991,\n",
              "         -0.09617991, -0.09367991],\n",
              "        [-0.07117991, -0.08534658, -0.08534658, ..., -0.09617991,\n",
              "         -0.09617991, -0.09617991],\n",
              "        [-0.07534658, -0.08534658, -0.08701324, ..., -0.09867991,\n",
              "         -0.09867991, -0.09617991]],\n",
              "\n",
              "       [[ 0.06922994,  0.06922994,  0.06922994, ...,  0.06922994,\n",
              "          0.06922994,  0.06922994],\n",
              "        [ 0.06922994,  0.06922994,  0.06922994, ...,  0.06922994,\n",
              "          0.06922994,  0.06922994],\n",
              "        [ 0.06922994,  0.06922994,  0.06922994, ...,  0.06922994,\n",
              "          0.06922994,  0.06922994],\n",
              "        ...,\n",
              "        [-0.08410339, -0.08410339, -0.08410339, ...,  0.06922994,\n",
              "          0.06922994,  0.06922994],\n",
              "        [-0.08410339, -0.08410339, -0.08410339, ...,  0.06922994,\n",
              "          0.06922994,  0.06922994],\n",
              "        [-0.0866034 , -0.0866034 , -0.0866034 , ...,  0.06922994,\n",
              "          0.06922994,  0.06922994]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy9rVEgRTvGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_wrong_rgbd(file_path):\n",
        "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    while folder == \"datalab\":\n",
        "      folder=np.random.choice(glob.glob(file_path + \"*\"))    \n",
        "    mat=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue\n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat = np.asarray(mat)\n",
        "    mat_small=mat[140:340,220:420]\n",
        "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
        "    img.thumbnail((640,480))\n",
        "    img = np.asarray(img)\n",
        "    img = img[140:340,220:420]\n",
        "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
        "  #  plt.imshow(img)\n",
        "  #  plt.show()\n",
        "  #  plt.imshow(mat_small)\n",
        "  #  plt.show()\n",
        "    folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    while folder==folder2 or folder2==\"datalab\": #it activates if it chose the same folder\n",
        "        folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
        "    mat2=np.zeros((480,640), dtype='float32')\n",
        "    i=0\n",
        "    j=0\n",
        "    depth_file = np.random.choice(glob.glob(folder2 + \"/*.dat\"))\n",
        "    with open(depth_file) as file:\n",
        "        for line in file:\n",
        "            vals = line.split('\\t')\n",
        "            for val in vals:\n",
        "                if val == \"\\n\": continue \n",
        "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
        "                mat2[i][j]=float(int(val))\n",
        "                j+=1\n",
        "                j=j%640\n",
        "\n",
        "            i+=1\n",
        "        mat2 = np.asarray(mat2)\n",
        "    mat2_small=mat2[140:340,220:420]\n",
        "    img2 = Image.open(depth_file[:-5] + \"c.bmp\")\n",
        "    img2.thumbnail((640,480))\n",
        "    img2 = np.asarray(img2)\n",
        "    img2 = img2[140:340,220:420]\n",
        "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
        " #   plt.imshow(img2)\n",
        " #   plt.show()\n",
        " #   plt.imshow(mat2_small)\n",
        " #   plt.show()\n",
        "    full1 = np.zeros((200,200,4))\n",
        "    full1[:,:,:3] = img[:,:,:3]\n",
        "    full1[:,:,3] = mat_small\n",
        "    \n",
        "    full2 = np.zeros((200,200,4))\n",
        "    full2[:,:,:3] = img2[:,:,:3]\n",
        "    full2[:,:,3] = mat2_small\n",
        "    return np.array([full1, full2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8rsfwckTwyl",
        "colab_type": "code",
        "outputId": "d586db58-0e11-4473-8b0c-6a9b58c61c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "create_wrong_rgbd(\"faceid_val/\")[0].shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcWnN11DT0_c",
        "colab_type": "text"
      },
      "source": [
        "# Network crafting.\n",
        "Now we create the network. We first manually create the *constrative loss*, then we define the network architecture starting from the SqueezeNet architecture, and then using it as a siamese-network for embedding faces into a manifold. (the network for now is very big and could be heavily optimized, but I just wanted to show a proof-of-concept)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIIZEPigT1md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Lambda, ELU, concatenate, GlobalAveragePooling2D, Input, BatchNormalization, SeparableConv2D, Subtract, concatenate\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htZqi0aWT4S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(inputs):\n",
        "    assert len(inputs) == 2, \\\n",
        "        'Euclidean distance needs 2 inputs, %d given' % len(inputs)\n",
        "    u, v = inputs\n",
        "    return K.sqrt(K.sum((K.square(u - v)), axis=1, keepdims=True))\n",
        "        \n",
        "\n",
        "def contrastive_loss(y_true,y_pred):\n",
        "    margin=1.\n",
        "    return K.mean((1. - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0.)))\n",
        "   # return K.mean( K.square(y_pred) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkXFh3FJT52w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fire(x, squeeze=16, expand=64):\n",
        "    x = Convolution2D(squeeze, (1,1), padding='valid')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    left = Convolution2D(expand, (1,1), padding='valid')(x)\n",
        "    left = Activation('relu')(left)\n",
        "    \n",
        "    right = Convolution2D(expand, (3,3), padding='same')(x)\n",
        "    right = Activation('relu')(right)\n",
        "    \n",
        "    x = concatenate([left, right], axis=3)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lioSL2nPT7BL",
        "colab_type": "code",
        "outputId": "d7c76947-1b78-48e8-a9c3-f4c1f526d00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "img_input=Input(shape=(200,200,4))\n",
        "\n",
        "x = Convolution2D(64, (5, 5), strides=(2, 2), padding='valid')(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
        "\n",
        "x = fire(x, squeeze=16, expand=16)\n",
        "x = fire(x, squeeze=16, expand=16)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
        "\n",
        "\n",
        "x = fire(x, squeeze=32, expand=32)\n",
        "x = fire(x, squeeze=32, expand=32)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
        "\n",
        "x = fire(x, squeeze=48, expand=48)\n",
        "x = fire(x, squeeze=48, expand=48)\n",
        "x = fire(x, squeeze=64, expand=64)\n",
        "x = fire(x, squeeze=64, expand=64)\n",
        "\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Convolution2D(512, (1, 1), padding='same')(x)\n",
        "out = Activation('relu')(x)\n",
        "\n",
        "modelsqueeze= Model(img_input, out)\n",
        "modelsqueeze.summary()\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 4) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 98, 98, 64)   6464        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 98, 98, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 98, 98, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 48, 48, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 48, 48, 16)   1040        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 48, 48, 16)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 48, 48, 16)   272         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 48, 48, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 48, 48, 16)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 48, 48, 16)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48, 48, 32)   0           activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 48, 48, 16)   528         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 48, 48, 16)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 48, 48, 16)   272         activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 48, 48, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 48, 48, 16)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 48, 48, 16)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 48, 48, 32)   0           activation_5[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 23, 23, 32)   0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 23, 23, 32)   1056        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 23, 23, 32)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 23, 23, 32)   1056        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 23, 23, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 23, 23, 32)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 23, 23, 32)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 23, 23, 64)   0           activation_8[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 23, 23, 32)   2080        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 32)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 23, 23, 32)   1056        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 23, 23, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 32)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 32)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 23, 23, 64)   0           activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 64)   0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 11, 11, 48)   3120        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 11, 11, 48)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 11, 11, 48)   2352        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 11, 11, 48)   20784       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 11, 11, 48)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 11, 11, 48)   0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 11, 11, 96)   0           activation_14[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 11, 11, 48)   4656        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 11, 11, 48)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 11, 11, 48)   2352        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 11, 11, 48)   20784       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 11, 11, 48)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 11, 11, 48)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 11, 11, 96)   0           activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 11, 11, 64)   6208        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 11, 11, 64)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 11, 11, 64)   4160        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 11, 11, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 11, 11, 64)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 11, 11, 64)   0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 11, 11, 128)  0           activation_20[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 11, 11, 64)   8256        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 11, 11, 64)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 11, 11, 64)   4160        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 11, 11, 64)   36928       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 11, 11, 64)   0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 11, 11, 64)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 11, 11, 128)  0           activation_23[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 11, 11, 128)  0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 11, 11, 512)  66048       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 11, 11, 512)  0           conv2d_25[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 253,952\n",
            "Trainable params: 253,824\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weCN_Y1yT8Y0",
        "colab_type": "code",
        "outputId": "34998c1b-3459-4111-f05c-f2059d90a662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "im_in = Input(shape=(200,200,4))\n",
        "#wrong = Input(shape=(200,200,3))\n",
        "\n",
        "x1 = modelsqueeze(im_in)\n",
        "#x = Convolution2D(64, (5, 5), padding='valid', strides =(2,2))(x)\n",
        "\n",
        "#x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x1)\n",
        "\n",
        "\"\"\"\n",
        "x1 = Convolution2D(256, (3,3), padding='valid', activation=\"relu\")(x1)\n",
        "x1 = Dropout(0.4)(x1)\n",
        "\n",
        "x1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1))(x1)\n",
        "\n",
        "x1 = Convolution2D(256, (3,3), padding='valid', activation=\"relu\")(x1)\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Dropout(0.4)(x1)\n",
        "\n",
        "x1 = Convolution2D(64, (1,1), padding='same', activation=\"relu\")(x1)\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Dropout(0.4)(x1)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "x1 = Dense(512, activation=\"relu\")(x1)\n",
        "x1 = Dropout(0.2)(x1)\n",
        "#x1 = BatchNormalization()(x1)\n",
        "feat_x = Dense(128, activation=\"linear\")(x1)\n",
        "feat_x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(feat_x)\n",
        "\n",
        "\n",
        "model_top = Model(inputs = [im_in], outputs = feat_x)\n",
        "\n",
        "model_top.summary()\n",
        "\n",
        "im_in1 = Input(shape=(200,200,4))\n",
        "im_in2 = Input(shape=(200,200,4))\n",
        "\n",
        "feat_x1 = model_top(im_in1)\n",
        "feat_x2 = model_top(im_in2)\n",
        "\n",
        "\n",
        "lambda_merge = Lambda(euclidean_distance)([feat_x1, feat_x2])\n",
        "\n",
        "\n",
        "model_final = Model(inputs = [im_in1, im_in2], outputs = lambda_merge)\n",
        "\n",
        "model_final.summary()\n",
        "\n",
        "adam = Adam(lr=0.001)\n",
        "\n",
        "sgd = SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "model_final.compile(optimizer=adam, loss=contrastive_loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 200, 200, 4)]     0         \n",
            "_________________________________________________________________\n",
            "model (Model)                (None, 11, 11, 512)       253952    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 61952)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               31719936  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 32,039,552\n",
            "Trainable params: 32,039,424\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 200, 200, 4) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 200, 200, 4) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 128)          32039552    input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n",
            "                                                                 model_1[2][0]                    \n",
            "==================================================================================================\n",
            "Total params: 32,039,552\n",
            "Trainable params: 32,039,424\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCvMGPUXUBQW",
        "colab_type": "text"
      },
      "source": [
        "# Learning phase.\n",
        "We write the generators that will give our model batches of data to train on, then we run the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jgGt8-6T-Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(batch_size):\n",
        "  \n",
        "  while 1:\n",
        "    X=[]\n",
        "    y=[]\n",
        "    switch=True\n",
        "    for _ in range(batch_size):\n",
        "   #   switch += 1\n",
        "      if switch:\n",
        "     #   print(\"correct\")\n",
        "        X.append(create_couple_rgbd(\"faceid_train/\").reshape((2,200,200,4)))\n",
        "        y.append(np.array([0.]))\n",
        "      else:\n",
        "     #   print(\"wrong\")\n",
        "        X.append(create_wrong_rgbd(\"faceid_train/\").reshape((2,200,200,4)))\n",
        "        y.append(np.array([1.]))\n",
        "      switch=not switch\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    XX1=X[0,:]\n",
        "    XX2=X[1,:]\n",
        "    yield [X[:,0],X[:,1]],y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9OXO0BhUDf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_generator(batch_size):\n",
        "  \n",
        "  while 1:\n",
        "    X=[]\n",
        "    y=[]\n",
        "    switch=True\n",
        "    for _ in range(batch_size):\n",
        "      if switch:\n",
        "        X.append(create_couple_rgbd(\"faceid_val/\").reshape((2,200,200,4)))\n",
        "        y.append(np.array([0.]))\n",
        "      else:\n",
        "        X.append(create_wrong_rgbd(\"faceid_val/\").reshape((2,200,200,4)))\n",
        "        y.append(np.array([1.]))\n",
        "      switch=not switch\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    XX1=X[0,:]\n",
        "    XX2=X[1,:]\n",
        "    yield [X[:,0],X[:,1]],y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy0-c1mGUEhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = generator(16)\n",
        "val_gen = val_generator(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu7e_dC4UFmi",
        "colab_type": "code",
        "outputId": "4193f3f8-a8d3-4004-f6af-2bc9c59af88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "outputs = model_final.fit_generator(gen, steps_per_epoch=30, epochs=50, validation_data = val_gen, validation_steps=20)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "29/30 [============================>.] - ETA: 13s - loss: 0.2555Epoch 1/50\n",
            "30/30 [==============================] - 514s 17s/step - loss: 0.2548 - val_loss: 0.4564\n",
            "Epoch 2/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.2275Epoch 1/50\n",
            "30/30 [==============================] - 445s 15s/step - loss: 0.2279 - val_loss: 0.2309\n",
            "Epoch 3/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1695Epoch 1/50\n",
            "30/30 [==============================] - 444s 15s/step - loss: 0.1687 - val_loss: 0.1786\n",
            "Epoch 4/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1439Epoch 1/50\n",
            "30/30 [==============================] - 445s 15s/step - loss: 0.1446 - val_loss: 0.1383\n",
            "Epoch 5/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1360Epoch 1/50\n",
            "30/30 [==============================] - 440s 15s/step - loss: 0.1363 - val_loss: 0.1118\n",
            "Epoch 6/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1237Epoch 1/50\n",
            "30/30 [==============================] - 434s 14s/step - loss: 0.1238 - val_loss: 0.1683\n",
            "Epoch 7/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1206Epoch 1/50\n",
            "30/30 [==============================] - 435s 15s/step - loss: 0.1196 - val_loss: 0.1724\n",
            "Epoch 8/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1186Epoch 1/50\n",
            "30/30 [==============================] - 434s 14s/step - loss: 0.1180 - val_loss: 0.0970\n",
            "Epoch 9/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1137Epoch 1/50\n",
            "30/30 [==============================] - 431s 14s/step - loss: 0.1137 - val_loss: 0.1258\n",
            "Epoch 10/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.1039Epoch 1/50\n",
            "30/30 [==============================] - 436s 15s/step - loss: 0.1030 - val_loss: 0.1411\n",
            "Epoch 11/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0863Epoch 1/50\n",
            "30/30 [==============================] - 438s 15s/step - loss: 0.0854 - val_loss: 0.0860\n",
            "Epoch 12/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0856Epoch 1/50\n",
            "30/30 [==============================] - 437s 15s/step - loss: 0.0847 - val_loss: 0.1084\n",
            "Epoch 13/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0694Epoch 1/50\n",
            "30/30 [==============================] - 437s 15s/step - loss: 0.0691 - val_loss: 0.0961\n",
            "Epoch 14/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0784Epoch 1/50\n",
            "30/30 [==============================] - 441s 15s/step - loss: 0.0780 - val_loss: 0.1264\n",
            "Epoch 15/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0729Epoch 1/50\n",
            "30/30 [==============================] - 441s 15s/step - loss: 0.0718 - val_loss: 0.1469\n",
            "Epoch 16/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0587Epoch 1/50\n",
            "30/30 [==============================] - 440s 15s/step - loss: 0.0592 - val_loss: 0.0873\n",
            "Epoch 17/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0653Epoch 1/50\n",
            "30/30 [==============================] - 439s 15s/step - loss: 0.0651 - val_loss: 0.1002\n",
            "Epoch 18/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0556Epoch 1/50\n",
            "30/30 [==============================] - 439s 15s/step - loss: 0.0563 - val_loss: 0.1330\n",
            "Epoch 19/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0520Epoch 1/50\n",
            "30/30 [==============================] - 437s 15s/step - loss: 0.0528 - val_loss: 0.0923\n",
            "Epoch 20/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0559Epoch 1/50\n",
            "30/30 [==============================] - 436s 15s/step - loss: 0.0566 - val_loss: 0.1043\n",
            "Epoch 21/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0604Epoch 1/50\n",
            "30/30 [==============================] - 437s 15s/step - loss: 0.0609 - val_loss: 0.2518\n",
            "Epoch 22/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0531Epoch 1/50\n",
            "30/30 [==============================] - 438s 15s/step - loss: 0.0528 - val_loss: 0.1166\n",
            "Epoch 23/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0381Epoch 1/50\n",
            "30/30 [==============================] - 437s 15s/step - loss: 0.0377 - val_loss: 0.1435\n",
            "Epoch 24/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0541Epoch 1/50\n",
            "30/30 [==============================] - 440s 15s/step - loss: 0.0539 - val_loss: 0.1242\n",
            "Epoch 25/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0480Epoch 1/50\n",
            "30/30 [==============================] - 442s 15s/step - loss: 0.0474 - val_loss: 0.1629\n",
            "Epoch 26/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0495Epoch 1/50\n",
            "30/30 [==============================] - 437s 15s/step - loss: 0.0490 - val_loss: 0.1514\n",
            "Epoch 27/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0471Epoch 1/50\n",
            "30/30 [==============================] - 441s 15s/step - loss: 0.0467 - val_loss: 0.1523\n",
            "Epoch 28/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0367Epoch 1/50\n",
            "30/30 [==============================] - 438s 15s/step - loss: 0.0365 - val_loss: 0.1671\n",
            "Epoch 29/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0488Epoch 1/50\n",
            "30/30 [==============================] - 440s 15s/step - loss: 0.0494 - val_loss: 0.1485\n",
            "Epoch 30/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0406Epoch 1/50\n",
            "30/30 [==============================] - 439s 15s/step - loss: 0.0412 - val_loss: 0.1383\n",
            "Epoch 31/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0379Epoch 1/50\n",
            "30/30 [==============================] - 441s 15s/step - loss: 0.0386 - val_loss: 0.0869\n",
            "Epoch 32/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0348Epoch 1/50\n",
            "30/30 [==============================] - 444s 15s/step - loss: 0.0341 - val_loss: 0.1658\n",
            "Epoch 33/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0279Epoch 1/50\n",
            "30/30 [==============================] - 442s 15s/step - loss: 0.0278 - val_loss: 0.1635\n",
            "Epoch 34/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0356Epoch 1/50\n",
            "30/30 [==============================] - 441s 15s/step - loss: 0.0360 - val_loss: 0.1693\n",
            "Epoch 35/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0374Epoch 1/50\n",
            "30/30 [==============================] - 445s 15s/step - loss: 0.0366 - val_loss: 0.1521\n",
            "Epoch 36/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0303Epoch 1/50\n",
            "30/30 [==============================] - 442s 15s/step - loss: 0.0309 - val_loss: 0.1627\n",
            "Epoch 37/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0392Epoch 1/50\n",
            "30/30 [==============================] - 440s 15s/step - loss: 0.0385 - val_loss: 0.1877\n",
            "Epoch 38/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0347Epoch 1/50\n",
            "30/30 [==============================] - 442s 15s/step - loss: 0.0348 - val_loss: 0.2482\n",
            "Epoch 39/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0327Epoch 1/50\n",
            "30/30 [==============================] - 436s 15s/step - loss: 0.0321 - val_loss: 0.1893\n",
            "Epoch 40/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0325Epoch 1/50\n",
            "30/30 [==============================] - 433s 14s/step - loss: 0.0330 - val_loss: 0.1213\n",
            "Epoch 41/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0363Epoch 1/50\n",
            "30/30 [==============================] - 435s 14s/step - loss: 0.0356 - val_loss: 0.1491\n",
            "Epoch 42/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0325Epoch 1/50\n",
            "30/30 [==============================] - 438s 15s/step - loss: 0.0324 - val_loss: 0.1367\n",
            "Epoch 43/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0326Epoch 1/50\n",
            "30/30 [==============================] - 438s 15s/step - loss: 0.0341 - val_loss: 0.1582\n",
            "Epoch 44/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0310Epoch 1/50\n",
            "30/30 [==============================] - 436s 15s/step - loss: 0.0303 - val_loss: 0.1374\n",
            "Epoch 45/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0317Epoch 1/50\n",
            "30/30 [==============================] - 437s 15s/step - loss: 0.0312 - val_loss: 0.3004\n",
            "Epoch 46/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0303Epoch 1/50\n",
            "30/30 [==============================] - 436s 15s/step - loss: 0.0299 - val_loss: 0.2063\n",
            "Epoch 47/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0385Epoch 1/50\n",
            "30/30 [==============================] - 427s 14s/step - loss: 0.0380 - val_loss: 0.1866\n",
            "Epoch 48/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0300Epoch 1/50\n",
            "30/30 [==============================] - 424s 14s/step - loss: 0.0298 - val_loss: 0.2581\n",
            "Epoch 49/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0365Epoch 1/50\n",
            "30/30 [==============================] - 427s 14s/step - loss: 0.0358 - val_loss: 0.2062\n",
            "Epoch 50/50\n",
            "29/30 [============================>.] - ETA: 10s - loss: 0.0276Epoch 1/50\n",
            "30/30 [==============================] - 422s 14s/step - loss: 0.0274 - val_loss: 0.1577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poRecgAfgka8",
        "colab_type": "text"
      },
      "source": [
        "# Some model tests.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8f5CwpuUHG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "fd122e57-6bdc-4e18-aca1-d909b938bafd"
      },
      "source": [
        "cop = create_couple(\"faceid_val/\")\n",
        "model_final.predict([cop[0].reshape((1,200,200,1)), cop[1].reshape((1,100,100,4))])\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-4177146dd9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_couple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"faceid_val/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 716\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    717\u001b[0m     return predict_loop(\n\u001b[1;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    570\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    573\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_3 to have shape (200, 200, 4) but got array with shape (200, 200, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJf9EVtOgoVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e65a81e2-278b-4039-cfc9-a95e7b3f9a7e"
      },
      "source": [
        "cop = create_wrong_rgbd(\"faceid_val/\")\n",
        "model_final.predict([cop[0].reshape((1,200,200,4)), cop[1].reshape((1,200,200,4))])\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38882995]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgLMqWw4gqNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6C9XEtQgsi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "eb332b01-77bf-4459-c1ac-96851f9eced7"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-73bc877a07db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iP7N7yWirpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}